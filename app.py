import streamlit as st
import pandas as pd
import os
import re
import io

# --- 1. é…ç½®èˆ‡æ ¸å¿ƒé‚è¼¯ (æ•´åˆ data_merge.py çš„æ‰€æœ‰åŠŸèƒ½) ---

def standardize_unit(val, mapping):
    """æ¨™æº–åŒ–å–®ä½æ¬„ä½ï¼Œæ”¯æ´é€²éšæŸ¥æ‰¾èˆ‡æš´åŠ›å»ç©ºç™½"""
    if pd.isna(val) or not isinstance(val, str):
        return val
    
    # 1. å¾¹åº•æ¶ˆé™¤æ‰€æœ‰ç©ºç™½ (æš´åŠ›æ³•) - ä¾†è‡ª data_merge.py
    val = "".join(val.split())
    
    # 2. è½‰å¤§å¯« (ç¢ºä¿ä¸€è‡´æ€§)
    val = val.upper()
    
    # 3. æª¢æŸ¥æ˜¯å¦å·²ç¶“æ˜¯æ­£ç¢ºæ ¼å¼ (å‰5ç¢¼è‹±æ•¸ + å¾Œé¢æœ‰ä¸­æ–‡å…§å®¹) - ä¾†è‡ª data_merge.py
    # åŸæœ¬ app.py æ˜¯å¯« [a-zA-Z]{2,}\d{3}ï¼Œé€™è£¡æ”¹ç”¨ data_merge çš„é€šç”¨æ ¼å¼ [a-zA-Z0-9]{5}.+
    if re.match(r"^[A-Z0-9]{5}.+", val):
        return val
    
    # 4. å¦‚æœ val ç›´æ¥åœ¨ mapping ä¸­ (åªæœ‰ä»£ç¢¼ æˆ– åªæœ‰åç¨±)
    if val in mapping:
        target = mapping[val]
        # å¦‚æœè¼¸å…¥æ˜¯ 5 ç¢¼ä»£ç¢¼
        if re.match(r"^[A-Z0-9]{5}$", val): 
            return f"{val}{target}"
        else: # å¦‚æœè¼¸å…¥æ˜¯ç´”ä¸­æ–‡åç¨±
            return f"{target}{val}"
    
    # 5. ã€é€²éšæŸ¥æ‰¾ã€‘ - ä¾†è‡ª data_merge.py
    # å˜—è©¦å¾å­—ä¸²ä¸­æŠ½å‡º 5 ç¢¼ä»£ç¢¼ä¾†å°ç…§ (ä¾‹å¦‚è¼¸å…¥ "å¯Œå®…TP838" -> æå– "TP838")
    found_code = re.search(r"[A-Z0-9]{5}", val)
    if found_code:
        code = found_code.group()
        if code in mapping:
            return f"{code}{mapping[code]}"
            
    return val

def process_data(uploaded_file, mapping_dict):
    """è™•ç†å–®ä¸€ä¸Šå‚³æª”æ¡ˆçš„æ¸…ç†æµç¨‹ (æ•´åˆ data_merge çš„éæ¿¾æ¢ä»¶)"""
    # è®€å–æª”æ¡ˆï¼Œè·³éç¬¬ä¸€åˆ— (skiprows=1)
    df = pd.read_csv(uploaded_file, skiprows=1, encoding='utf-8-sig')
    
    # ç§»é™¤ã€Œåºã€èˆ‡ã€Œé€£çµ¡é›»è©±ã€ç©ºç™½çš„è³‡æ–™
    df = df.dropna(subset=['åº', 'é€£çµ¡é›»è©±'])
    
    # æ’é™¤åŒ…å«ã€Œå–æ¶ˆã€å­—æ¨£çš„è³‡æ–™
    df = df[~df['åº'].astype(str).str.contains('å–æ¶ˆ')]
    
    # æå–ã€Œå–®ä½ã€å’Œã€Œå§“åã€
    extracted_data = df[['å–®ä½', 'å§“å']].copy()
    
    # æ¸…ç†å­—ä¸²å…§å®¹ - æ•´åˆäº† data_merge.py çš„ replace è¦å‰‡ (åŒ…å« -, ä¸€åˆ†è™•, ã„§, åˆ†è™•ç­‰)
    extracted_data = extracted_data.replace(r'\s+', '', regex=True)
    extracted_data = extracted_data.replace(['-', 'ä¸€åˆ†è™•', 'ä¸€', 'ã„§', 'åˆ†è™•'], '', regex=True)
    
    # çµ±ä¸€è½‰å¤§å¯«ä¸¦åŸ·è¡Œæ¨™æº–åŒ–
    extracted_data['å–®ä½'] = extracted_data['å–®ä½'].str.upper()
    extracted_data['å–®ä½'] = extracted_data['å–®ä½'].apply(lambda x: standardize_unit(x, mapping_dict))
    
    return extracted_data

# --- 2. Streamlit ç¶²é ä»‹é¢ ---

st.set_page_config(page_title="RFA å ±åç®¡ç†ç³»çµ±", layout="wide")
st.title("ğŸ“Š RFA å ±åè³‡æ–™å¢é‡æ›´æ–°ç³»çµ±")

# è¨­å®šè·¯å¾‘ (ä½¿ç”¨ä½  data_merge.py ä¸­çš„ Excel è·¯å¾‘)
MASTER_DB_PATH = 'master_data.csv'
REF_PATH = 'FB11407Fé€šè¨Šè™•20260101.xlsx'

# è®€å–å°ç…§è¡¨ (æ•´åˆ data_merge.py çš„ Excel æ¸…æ´—é‚è¼¯)
@st.cache_data
def get_mapping():
    try:
        # è®€å– Excel ä¸¦å¥—ç”¨ data_merge çš„æ¸…æ´—æµç¨‹
        ref_raw = pd.read_excel(REF_PATH, skiprows=1) 
        ref_df = ref_raw[['ä»£ç¢¼', 'å–®ä½åç¨±']].copy()
        
        # ç§»é™¤æ¨™é¡Œå­—çœ¼èˆ‡ç©ºç™½
        ref_df = ref_df.replace(['é€šè¨Šè™•', 'ä»£ç¢¼', 'å–®ä½åç¨±'], '', regex=True)
        ref_df = ref_df.replace(r'\s+', '', regex=True)
        
        # æ¬„ä½æ ¼å¼åŒ–
        ref_df['ä»£ç¢¼'] = ref_df['ä»£ç¢¼'].astype(str).str.strip().str.upper()
        ref_df['å–®ä½åç¨±'] = ref_df['å–®ä½åç¨±'].astype(str).str.strip()
        
        # ç§»é™¤ç©ºå€¼èˆ‡ç„¡æ•ˆå­—ä¸² (nan)
        ref_df = ref_df.dropna(subset=['å–®ä½åç¨±']) 
        ref_df = ref_df[~ref_df['å–®ä½åç¨±'].isin(['', 'nan'])]
        
        # å»ºç«‹é›™å‘å­—å…¸
        m = dict(zip(ref_df['ä»£ç¢¼'], ref_df['å–®ä½åç¨±']))
        m.update(dict(zip(ref_df['å–®ä½åç¨±'], ref_df['ä»£ç¢¼'])))
        return m
    except Exception as e:
        st.error(f"âš ï¸ å°ç…§è¡¨è®€å–å¤±æ•—ï¼Œè«‹ç¢ºèªè·¯å¾‘ï¼š{REF_PATH}")
        st.error(f"éŒ¯èª¤è¨Šæ¯: {e}")
        return {}

mapping_dict = get_mapping()

# å´é‚Šæ¬„ï¼šé¡¯ç¤ºç•¶å‰ä¸»è³‡æ–™åº«ç‹€æ…‹
if os.path.exists(MASTER_DB_PATH):
    # å¼·åˆ¶è®€å–ç‚ºå­—ä¸²é¿å… ID è¢«ç§‘å­¸ç¬¦è™ŸåŒ–
    master_df = pd.read_csv(MASTER_DB_PATH)
    st.sidebar.success(f"ğŸ—ƒï¸ ç›®å‰è³‡æ–™åº«å·²æœ‰: {len(master_df)} ç­†è³‡æ–™")
else:
    master_df = pd.DataFrame(columns=['å–®ä½', 'å§“å'])
    st.sidebar.info("ğŸ“‚ ç›®å‰è³‡æ–™åº«ç‚ºç©º")

# --- 3. æª”æ¡ˆä¸Šå‚³å€ ---
st.subheader("ç¬¬ä¸€æ­¥ï¼šä¸Šå‚³æ–°è³‡æ–™")
uploaded_files = st.file_uploader("é¸æ“‡ RFA å ±å CSV æª”æ¡ˆ (æ”¯æ´å¤šé¸)", type="csv", accept_multiple_files=True)

if uploaded_files:
    all_new_frames = []
    for f in uploaded_files:
        temp_df = process_data(f, mapping_dict)
        all_new_frames.append(temp_df)
    
    current_batch_df = pd.concat(all_new_frames, ignore_index=True)
    
    st.write("ğŸ” æœ¬æ¬¡ä¸Šå‚³é è¦½ï¼š")
    st.dataframe(current_batch_df.head(), use_container_width=True)

    # --- 4. å¢é‡æ›´æ–°æŒ‰éˆ• ---
    if st.button("ğŸš€ ç¢ºèªåˆä½µè‡³ä¸»è³‡æ–™åº«"):
        # åˆä½µèˆŠè³‡æ–™èˆ‡æ–°è³‡æ–™
        # ä»¥ã€Œå–®ä½+å§“åã€ä½œç‚ºå”¯ä¸€åŸºæº–é¿å…é‡è¤‡é‡è¤‡
        final_df = pd.concat([master_df, current_batch_df], ignore_index=True)
        final_df = final_df.drop_duplicates(subset=['å–®ä½', 'å§“å'], keep='last')
        
        final_df.to_csv(MASTER_DB_PATH, index=False, encoding='utf-8-sig')
        st.balloons()
        st.success(f"âœ… æ›´æ–°æˆåŠŸï¼ç›®å‰ç¸½æ•¸ï¼š{len(final_df)} ç­†ã€‚")
        master_df = final_df # å³æ™‚æ›´æ–°è®Šæ•¸ä¾›ä¸‹æ–¹çµ±è¨ˆé¡¯ç¤º

# --- 5. çµ±è¨ˆèˆ‡ä¸‹è¼‰å€ ---
if not master_df.empty:
    st.divider()
    st.subheader("ç¬¬äºŒæ­¥ï¼šæ•¸æ“šçµ±è¨ˆèˆ‡ä¸‹è¼‰")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # çµ±è¨ˆå„å–®ä½äººæ•¸
        summary_df = master_df.groupby('å–®ä½').size().reset_index(name='å ±åäººæ•¸')
        # ä¾äººæ•¸é™å†ªæ’åº
        summary_df = summary_df.sort_values(by='å ±åäººæ•¸', ascending=False)
        st.dataframe(summary_df, use_container_width=True)
    
    with col2:
        # ç”¢å‡º Excel ä¸‹è¼‰æµ
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            summary_df.to_excel(writer, sheet_name='äººæ•¸çµ±è¨ˆ', index=False)
            master_df.to_excel(writer, sheet_name='è©³ç´°åå–®', index=False)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´çµ±è¨ˆ Excel å ±è¡¨",
            data=buffer.getvalue(),
            file_name=f"RFAå ±åçµ±è¨ˆè¡¨_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )